# Proyecto de An√°lisis de Datos P2P (Versi√≥n Profesional) üöÄ

Este proyecto proporciona una soluci√≥n integral para el an√°lisis avanzado de datos de operaciones Peer-to-Peer (P2P), com√∫nmente exportados desde plataformas de intercambio de criptomonedas como Binance. Utilizando el poder y la eficiencia de la biblioteca **Polars** para el backend de procesamiento de datos, el script principal ingiere un archivo CSV, realiza una limpieza y transformaci√≥n exhaustiva de los datos, calcula un amplio espectro de m√©tricas financieras y de actividad, genera m√∫ltiples tablas de resumen detalladas, crea visualizaciones informativas con `matplotlib` y `seaborn`, y consolida toda esta informaci√≥n en reportes HTML interactivos.

Una caracter√≠stica distintiva es su capacidad para organizar los resultados de forma meticulosa: no solo para el conjunto de datos completo, sino tambi√©n desglosado por cada a√±o presente en los datos. Adem√°s, dentro de cada uno de estos periodos (total y anual), el an√°lisis se segmenta a√∫n m√°s seg√∫n el estado de la orden ‚Äî`Completadas`, `Canceladas`, y `Todas`‚Äî permitiendo una granularidad excepcional y una comprensi√≥n profunda de las din√°micas de las operaciones P2P.

## üìñ Tabla de Contenidos
1.  [üéØ Visi√≥n General del Proyecto](#-visi√≥n-general-del-proyecto)
2.  [üõ†Ô∏è Arquitectura del C√≥digo Fuente (`src/`)](#Ô∏è-arquitectura-del-c√≥digo-fuente-src)
    *   [`app.py`](#apppy)
    *   [`main_logic.py`](#main_logicpy)
    *   [`analyzer.py`](#analyzerpy)
    *   [`reporter.py`](#reporterpy)
    *   [`plotting.py`](#plottingpy)
    *   [`config_loader.py`](#config_loaderpy)
    *   [`utils.py`](#utilspy)
3.  [üåä Flujo de Procesamiento de Datos Detallado](#-flujo-de-procesamiento-de-datos-detallado)
4.  [‚öôÔ∏è Configuraci√≥n del Proyecto (`src/config_loader.py`)](#Ô∏è-configuraci√≥n-del-proyecto-srcconfig_loaderpy)
5.  [üìä Columnas Clave y Mapeo](#-columnas-clave-y-mapeo)
6.  [üìà M√©tricas Calculadas (`src/analyzer.py`)](#-m√©tricas-calculadas-srcanalyzerpy)
7.  [üñºÔ∏è Generaci√≥n de Salidas (`src/reporter.py` y `src/plotting.py`)](#Ô∏è-generaci√≥n-de-salidas-srcreporterpy-y-srcplottingpy)
8.  [üöÄ Uso Avanzado y Argumentos CLI](#-uso-avanzado-y-argumentos-cli)
9.  [üë®‚Äçüíª Gu√≠a para Desarrolladores](#-gu√≠a-para-desarrolladores)
10. [üîó Dependencias Clave](#-dependencias-clave)
11. [üîÑ Flujo de Procesamiento de Datos (Resumen Gr√°fico Simplificado)](#-flujo-de-procesamiento-de-datos-resumen-gr√°fico-simplificado)


## üéØ Visi√≥n General del Proyecto

El objetivo principal de este proyecto es ofrecer a los usuarios una herramienta robusta y flexible para convertir datos crudos de transacciones P2P en informaci√≥n accionable y f√°cil de interpretar. Est√° dirigido a traders activos, analistas financieros o cualquier persona que necesite un entendimiento detallado de su historial de operaciones P2P para optimizar estrategias, realizar declaraciones fiscales, o simplemente para llevar un control detallado de su actividad.

**Beneficios Clave:**
*   **An√°lisis Profundo y Automatizado:** Ahorra horas de procesamiento manual de datos.
*   **Comprensi√≥n Granular:** El desglose por a√±o y estado de orden revela patrones que podr√≠an pasar desapercibidos.
*   **Salidas M√∫ltiples y Claras:** Tablas CSV para an√°lisis posterior, gr√°ficos para visualizaci√≥n r√°pida y reportes HTML para una presentaci√≥n completa.
*   **Eficiencia con Polars:** Manejo r√°pido de grandes vol√∫menes de datos gracias a Polars, un motor de procesamiento de DataFrames escrito en Rust.
*   **Personalizaci√≥n v√≠a CLI:** Adaptabilidad a diferentes necesidades de filtrado y an√°lisis mediante una interfaz de l√≠nea de comandos intuitiva.
*   **Resultados Organizados:** Una estructura de directorios clara para los archivos de salida (`output/`), facilitando el acceso y la revisi√≥n.

## üõ†Ô∏è Arquitectura del C√≥digo Fuente (`src/`)

Esta secci√≥n describe los m√≥dulos principales que componen el proyecto y sus responsabilidades.

*   **`app.py`**:
    *   **Rol:** Punto de entrada principal de la aplicaci√≥n CLI (Command Line Interface). Es el script que el usuario ejecuta directamente.
    *   **Responsabilidades:**
        *   Utiliza `main_logic.initialize_analysis` para definir y parsear los argumentos proporcionados por el usuario en la l√≠nea de comandos.
        *   Carga la configuraci√≥n base del proyecto mediante `config_loader.load_config`.
        *   Lee el archivo CSV de entrada especificado por el usuario (argumento `--csv`) utilizando Polars, aplicando inferencia de esquema y manejo de valores nulos.
        *   Realiza un mapeo inicial de columnas: renombra las columnas del CSV a los nombres internos estandarizados definidos en `config['column_mapping']`.
        *   Aplica filtros globales al DataFrame cargado, basados en los argumentos opcionales de la CLI (como `--fiat_filter`, `--asset_filter`, `--status_filter`, `--payment_method_filter`).
        *   Realiza una primera pasada de procesamiento llamando a `analyzer.analyze` sobre el DataFrame (ya filtrado por CLI) para generar columnas base necesarias para el desglose (ej. `Year`).
        *   Orquesta el pipeline de an√°lisis principal invocando `main_logic.run_analysis_pipeline`, pas√°ndole el DataFrame pre-procesado, los argumentos CLI, la configuraci√≥n, etc.

*   **`main_logic.py`**:
    *   **Rol:** Contiene la l√≥gica de orquestaci√≥n para el parseo de argumentos y el pipeline de an√°lisis segmentado.
    *   **Responsabilidades:**
        *   **`initialize_analysis(cli_args_list=None)`**:
            *   Define todos los argumentos aceptados por la l√≠nea de comandos usando el m√≥dulo `argparse` (e.g., `--csv`, `--out`, `--fiat_filter`, `--no_annual_breakdown`).
            *   Procesa los argumentos recibidos.
            *   Construye sufijos de nombres de archivo (ej. `_fiat_UYU_asset_USDT`) y sufijos de t√≠tulos para los reportes, basados en los filtros CLI activos, para una f√°cil identificaci√≥n de las salidas.
            *   Devuelve los argumentos parseados (`args`), el sufijo limpio para nombres de archivo y el sufijo para t√≠tulos.
        *   **`run_analysis_pipeline(...)`**:
            *   Recibe el DataFrame maestro ya pre-procesado por `app.py`.
            *   Determina los "periodos" a procesar:
                *   Siempre incluye un periodo "total" que corresponde al DataFrame maestro completo.
                *   Si no se especifica `--no_annual_breakdown` y la columna `Year` est√° disponible, identifica todos los a√±os √∫nicos en los datos y crea un DataFrame filtrado para cada a√±o, a√±adi√©ndolo como un periodo adicional a procesar.
            *   Itera sobre cada "periodo" determinado (ej. "total", "2022", "2023").
            *   Dentro de cada periodo, itera sobre las tres categor√≠as de estado definidas: `"todas"`, `"completadas"`, `"canceladas"`.
            *   Para la combinaci√≥n actual de `periodo` y `status_category`:
                *   Filtra el DataFrame del periodo base para obtener el subconjunto de datos espec√≠fico (ej., datos de 2023 que est√©n "Completed", o todos los datos de "total" que sean "Cancelled" o "System cancelled").
                *   Si el subconjunto resultante est√° vac√≠o, se omite y se pasa a la siguiente iteraci√≥n.
                *   Llama a `analyzer.analyze` nuevamente, esta vez sobre este subconjunto espec√≠fico. Esto recalcula todas las m√©tricas granulares para esa combinaci√≥n particular de periodo y estado.
                *   Luego, llama a `reporter.save_outputs` para generar y guardar todas las salidas (tablas CSV, figuras PNG, reporte HTML) correspondientes a este subconjunto analizado.

*   **`analyzer.py`**:
    *   **Rol:** Es el coraz√≥n del procesamiento de datos y el c√°lculo de todas las m√©tricas num√©ricas y estad√≠sticas.
    *   **Responsabilidades (principalmente dentro de la funci√≥n `analyze`):**
        *   Recibe un DataFrame (que puede ser el global filtrado por CLI, o un subconjunto espec√≠fico de periodo/estado desde `main_logic.py`), el `col_map` y `sell_config`.
        *   **Transformaci√≥n y Creaci√≥n de Columnas Fundamentales:**
            *   **Columnas Num√©ricas:** Convierte columnas de texto que representan valores monetarios o cantidades (ej. `Price`, `Quantity`, `Total Price`, `Maker Fee`, `Taker Fee`) a tipos num√©ricos `Float64`. Utiliza `utils.parse_amount` para manejar posibles formatos con comas o diferentes separadores decimales. Si una columna mapeada no existe en el CSV, se crea como una columna de nulos para evitar errores posteriores.
            *   `TotalFee`: Calcula la comisi√≥n total sumando `MakerFee_num` y `TakerFee_num` (los nulos se tratan como 0).
            *   **Columnas de Tiempo:**
                *   Asegura la existencia de `Match_time_local` (hora local de la operaci√≥n). Si no existe o no es de tipo datetime, intenta crearla a partir de `match_time_utc` (la columna de tiempo UTC del CSV). Esta conversi√≥n incluye la localizaci√≥n a una zona horaria espec√≠fica (actualmente 'America/Montevideo').
                *   A partir de `Match_time_local`, deriva:
                    *   `hour_local`: La hora del d√≠a (0-23).
                    *   `YearMonthStr`: El a√±o y mes en formato 'YYYY-MM'.
                    *   `Year`: El a√±o como entero.
                *   Maneja robustamente la ausencia de la columna de tiempo original o errores en la conversi√≥n.
        *   **C√°lculo de un Diccionario de M√©tricas Agregadas (usando Polars):**
            *   `asset_stats`: Agrupado por `asset_type` y `order_type` (BUY/SELL). Calcula: `operations` (conteo), `quantity` (suma de `Quantity_num`), `total_fiat` (suma de `TotalPrice_num`), `total_fees` (suma de `TotalFee`).
            *   `fiat_stats`: Agrupado por `fiat_type` y `order_type`. Calcula: `operations`, `total_fiat`, `avg_price` (media de `Price_num`), `total_fees`.
            *   `price_stats`: Agrupado por `fiat_type`. Calcula estad√≠sticas descriptivas detalladas para `Price_num`: `avg_price`, `median_price`, `min_price`, `max_price`, `std_price`, `q1_price` (percentil 25), `q3_price` (percentil 75), `iqr_price` (rango intercuart√≠lico), `p1_price` (percentil 1), `p99_price` (percentil 99).
            *   `fees_stats`: Agrupado por `asset_type`. Calcula: `total_fees_collected`, `avg_fee_per_op`, `num_ops_with_fees` (conteo de operaciones con comisi√≥n > 0), `max_fee`.
            *   `monthly_fiat`: Agrupa por `YearMonthStr`, `fiat_type`, y `order_type` para sumar `TotalPrice_num`. Luego, pivota la tabla para tener `YearMonthStr` y `fiat_type` como √≠ndice, y columnas separadas para los vol√∫menes de BUY y SELL.
            *   `status_counts`: Conteo de operaciones por cada valor √∫nico en la columna `status`.
            *   `side_counts`: Conteo de operaciones por cada valor √∫nico en la columna `order_type` (generalmente BUY/SELL).
            *   `hourly_counts`: Conteo de operaciones por `hour_local`, ordenado por hora.
            *   `sales_summary_all_assets_fiat_detailed`: Esta m√©trica se calcula solo sobre operaciones 'Completed' que adem√°s coinciden con la configuraci√≥n de venta (`sell_config`). Agrupa por `asset_type` (Asset Sold) y `fiat_type` (Fiat Received). Calcula: `Total Asset Sold` (suma de `Quantity_num`), `Total Fiat Received` (suma de `TotalPrice_num`), y `Average Sell Price` (Fiat Recibido / Activo Vendido).
        *   La funci√≥n `analyze` devuelve una tupla: el DataFrame procesado (con todas las nuevas columnas num√©ricas y de tiempo) y el diccionario `metrics` que contiene todas las tablas de m√©tricas calculadas.

*   **`reporter.py`**:
    *   **Rol:** Responsable de tomar los datos procesados y las m√©tricas, y generar todas las salidas finales del an√°lisis: tablas CSV, figuras (gr√°ficos) y reportes HTML.
    *   **Responsabilidades (principalmente dentro de la funci√≥n `save_outputs`):**
        *   **Gesti√≥n de Rutas y Directorios:** Crea la estructura de carpetas de salida necesaria (`output/[periodo]/[estado_subdir]/tables/`, `figures/`, `reports/`) si no existe.
        *   **Conversi√≥n de Datos Polars a Pandas:** Convierte los DataFrames y Series de Polars (contenidos en `metrics_to_save` y `df_to_plot_from`) a sus equivalentes en Pandas, ya que las bibliotecas de gr√°ficos (`matplotlib`, `seaborn`) y la generaci√≥n de HTML de Pandas son m√°s directas con objetos Pandas.
        *   **Guardado de Tablas CSV:** Itera sobre cada m√©trica en `metrics_to_save_pandas`. Guarda cada DataFrame/Serie como un archivo `.csv` en la subcarpeta `tables/` correspondiente. Los nombres de archivo incluyen el sufijo CLI para identificaci√≥n.
        *   **Generaci√≥n y Guardado de Figuras:**
            *   Llama a las diversas funciones de `plotting.py` (ej. `plotting.plot_hourly`, `plotting.plot_monthly`, `plotting.plot_price_distribution`, etc.) pas√°ndoles los DataFrames de Pandas apropiados.
            *   Cada funci√≥n de ploteo guarda su gr√°fico como un archivo `.png` en la subcarpeta `figures/`.
            *   Mantiene una lista (`figures_for_html`) de las rutas relativas y t√≠tulos de las figuras generadas para incluirlas en el reporte HTML.
        *   **Generaci√≥n de Reportes HTML:**
            *   Carga la plantilla `report_template.html` usando el motor de plantillas Jinja2.
            *   Prepara un "contexto" (un diccionario Python) que se pasar√° a la plantilla. Este contexto incluye:
                *   T√≠tulo din√°mico del reporte (reflejando periodo, estado y filtros CLI).
                *   Marca de tiempo de generaci√≥n.
                *   Un resumen de los filtros CLI aplicados.
                *   El periodo analizado (ej. "A√±o 2023", "Total Consolidado").
                *   La categor√≠a de estado procesada (ej. "Completadas").
                *   Tablas de m√©tricas seleccionadas (seg√∫n `config['html_report']['include_tables_default']`), convertidas a formato string HTML usando `pandas.DataFrame.to_html()`.
                *   La lista `figures_for_html` para que la plantilla pueda incrustar las im√°genes.
            *   Renderiza la plantilla Jinja2 con este contexto, generando el contenido HTML final.
            *   Guarda el string HTML resultante en un archivo `.html` en la subcarpeta `reports/`.

*   **`plotting.py`**:
    *   **Rol:** M√≥dulo dedicado a la creaci√≥n de todas las visualizaciones gr√°ficas del proyecto.
    *   **Responsabilidades:**
        *   Contiene una serie de funciones, cada una nombrada `plot_*` (ej. `plot_hourly`, `plot_monthly`, `plot_pie`, `plot_price_distribution`, `plot_volume_vs_price_scatter`, `plot_activity_heatmap`).
        *   Cada funci√≥n es responsable de generar un tipo espec√≠fico de gr√°fico.
        *   Toma como entrada un DataFrame de Pandas (preparado y filtrado en `reporter.py`), el directorio de salida para las figuras, y sufijos para el t√≠tulo y el nombre del archivo.
        *   Utiliza `matplotlib.pyplot` y `seaborn` para construir los gr√°ficos.
        *   Se encarga de la configuraci√≥n est√©tica (colores, estilos), etiquetas de ejes, t√≠tulos de gr√°ficos, leyendas, y el guardado final del gr√°fico como un archivo PNG en la ruta especificada.
        *   Maneja casos donde los datos de entrada podr√≠an ser insuficientes para generar un gr√°fico, emitiendo logs y retornando `None` o una lista vac√≠a de rutas.
        *   (Ver secci√≥n "üìä Figuras Generadas" para una lista detallada).

*   **`config_loader.py`**:
    *   **Rol:** Centraliza la configuraci√≥n del proyecto.
    *   **Responsabilidades:**
        *   Define una constante `DEFAULT_CONFIG`, que es un diccionario Python sirviendo como la configuraci√≥n por defecto para la aplicaci√≥n. Esta configuraci√≥n incluye:
            *   `column_mapping`: Un diccionario crucial que mapea los nombres de las columnas esperados/deseados por el script (claves) a los nombres de columna tal como podr√≠an aparecer en el archivo CSV de entrada (valores). Esto permite flexibilidad si diferentes usuarios tienen CSVs con nombres de columna ligeramente distintos.
            *   `sell_operation`: Especifica qu√© columna (`indicator_column`) y qu√© valor (`indicator_value`) en esa columna identifican una operaci√≥n de venta. Usado para el `sales_summary_all_assets_fiat_detailed`.
            *   `reference_fiat_for_sales_summary`: (Actualmente "USD") Un fiat de referencia que podr√≠a usarse para normalizar o presentar res√∫menes de ventas (aunque su uso prominente no est√° implementado m√°s all√° de la configuraci√≥n).
            *   `html_report`: Define qu√© tablas de m√©tricas (`include_tables_default`) y qu√© tipos de figuras (`include_figures_default`, aunque esta √∫ltima parte parece no estar completamente implementada para seleccionar figuras espec√≠ficas por defecto) se deben incluir en los reportes HTML generados.
        *   Proporciona la funci√≥n `load_config()`, que actualmente solo devuelve una copia del `DEFAULT_CONFIG`. En futuras versiones, esta funci√≥n podr√≠a ser extendida para cargar configuraciones desde archivos externos (ej. YAML, JSON), permitiendo una personalizaci√≥n m√°s f√°cil sin modificar el c√≥digo fuente.

*   **`utils.py`**:
    *   **Rol:** Colecci√≥n de funciones de utilidad peque√±as y gen√©ricas usadas en otras partes del proyecto.
    *   **Responsabilidades:**
        *   **`parse_amount(val)`**: Una funci√≥n clave para la limpieza de datos. Toma un valor que puede ser un string (potencialmente con comas como separadores de miles o diferentes caracteres decimales), un entero o un flotante. Intenta convertirlo a un tipo `float` est√°ndar de Python. Si la conversi√≥n falla (ej. el string no es un n√∫mero v√°lido), devuelve `None` en lugar de causar un error, permitiendo un procesamiento m√°s robusto.

## üåä Flujo de Procesamiento de Datos Detallado

El flujo de datos y procesamiento en el proyecto se puede resumir en las siguientes etapas principales:

1.  **Inicio y Configuraci√≥n (`app.py` & `main_logic.py`)**:
    *   El usuario ejecuta `python src/app.py` con los argumentos CLI necesarios (m√≠nimo `--csv`).
    *   `main_logic.initialize_analysis` parsea estos argumentos y genera sufijos para nombres de archivo/t√≠tulos.
    *   `app.py` carga la configuraci√≥n por defecto desde `config_loader.load_config()`.

2.  **Carga y Mapeo Inicial de Datos (`app.py`)**:
    *   El archivo CSV especificado es le√≠do por Polars (`pl.read_csv`). Se especifican tipos para columnas de n√∫meros de orden para asegurar que se lean como strings.
    *   Las columnas del DataFrame cargado se renombran seg√∫n el `column_mapping` de la configuraci√≥n. Esto estandariza los nombres de las columnas para el resto del script.

3.  **Filtrado Global por CLI (`app.py`)**:
    *   El DataFrame se clona y se aplican los filtros opcionales de la l√≠nea de comandos:
        *   `--fiat_filter`: Filtra por moneda(s) fiat.
        *   `--asset_filter`: Filtra por tipo(s) de activo.
        *   `--status_filter`: Filtra por estado(s) de orden.
        *   `--payment_method_filter`: Filtra por m√©todo(s) de pago.
    *   Si el DataFrame queda vac√≠o despu√©s de estos filtros, el script termina.

4.  **Pre-procesamiento Base (`app.py` -> `analyzer.analyze`)**:
    *   Se llama a `analyzer.analyze` una vez con el DataFrame filtrado por CLI. El prop√≥sito principal de esta llamada inicial es asegurar que las columnas necesarias para el desglose posterior (especialmente `Year` derivada de `Match_time_local`) se generen en el `df_master_processed`. Las m√©tricas calculadas en esta etapa (variable `_` en `df_master_processed, _ = analyze(...)`) usualmente no se usan directamente, ya que el an√°lisis detallado ocurre despu√©s para cada subconjunto.
    *   Si `df_master_processed` est√° vac√≠o (ej., si todas las fechas son inv√°lidas), el script termina.

5.  **Pipeline de An√°lisis Segmentado (`app.py` -> `main_logic.run_analysis_pipeline`)**:
    *   `main_logic.run_analysis_pipeline` toma el control.
    *   **Determinaci√≥n de Periodos**:
        *   Se crea un periodo "total" usando `df_master_processed`.
        *   Si `--no_annual_breakdown` no est√° activo y la columna `Year` existe (y no es todo nulos), se extraen los a√±os √∫nicos y se crean DataFrames filtrados para cada a√±o, a√±adi√©ndolos a la lista de periodos a procesar.
    *   **Bucle Principal (Iteraci√≥n por Periodo y Estado)**:
        *   Se itera sobre cada `period_label` (ej. "total", "2022", "2023", ...).
        *   Dentro de cada periodo, se itera sobre `status_category` ("todas", "completadas", "canceladas").
        *   **Filtrado Espec√≠fico**: Se crea `df_subset_for_status` filtrando `df_period_base` (el DataFrame del periodo actual) seg√∫n la `status_category`:
            *   "todas": Se clona `df_period_base`.
            *   "completadas": Se filtra por `status == 'Completed'`.
            *   "canceladas": Se filtra por `status` siendo 'Cancelled' o 'System cancelled'.
        *   Si `df_subset_for_status` est√° vac√≠o, se omite esa combinaci√≥n y se pasa a la siguiente iteraci√≥n.
        *   **An√°lisis Detallado del Subconjunto (`main_logic.py` -> `analyzer.analyze`)**:
            *   Se llama a `analyzer.analyze` con `df_subset_for_status`. Esta es la llamada crucial donde se calculan todas las m√©tricas detalladas (`current_metrics`) para la combinaci√≥n espec√≠fica de periodo y estado. El `processed_df_for_save` devuelto contiene el subconjunto con todas las columnas transformadas (num√©ricas, de tiempo).
        *   **Generaci√≥n de Salidas (`main_logic.py` -> `reporter.save_outputs`)**:
            *   Se llama a `reporter.save_outputs` con `processed_df_for_save`, `current_metrics`, etiquetas de periodo y estado, configuraci√≥n, argumentos CLI, etc.
            *   `reporter.save_outputs` se encarga de:
                *   Crear la estructura de carpetas (`output/[period_label]/[status_category]/[tables|figures|reports]`).
                *   Convertir DataFrames y Series de Polars a Pandas para la generaci√≥n de gr√°ficos y algunas tablas HTML.
                *   Guardar las tablas de `current_metrics` en archivos CSV en la carpeta `tables/`.
                *   Llamar a las funciones correspondientes en `plotting.py` para generar los archivos PNG de los gr√°ficos, usando `processed_df_for_save` y las m√©tricas relevantes.
                *   Generar y guardar el reporte HTML, incluyendo las tablas de m√©tricas y las figuras generadas, en la carpeta `reports/`.

6.  **Finalizaci√≥n (`app.py`)**:
    *   Una vez que todos los bucles de `run_analysis_pipeline` han terminado, `app.py` imprime un mensaje de finalizaci√≥n indicando la ruta a la carpeta de salida principal.

## ‚öôÔ∏è Configuraci√≥n del Proyecto (`src/config_loader.py`)

La configuraci√≥n del proyecto se gestiona centralmente en `src/config_loader.py` a trav√©s de un diccionario Python llamado `DEFAULT_CONFIG`. Esto permite un f√°cil ajuste de ciertos comportamientos del script sin modificar la l√≥gica principal.

```python
DEFAULT_CONFIG = {
    'column_mapping': {
        'order_number': "Order Number",       # Nombre de columna en CSV para el n√∫mero de orden
        'order_type': "Order Type",         # Nombre para tipo de orden (BUY/SELL)
        'asset_type': "Asset Type",         # Nombre para tipo de activo (ej. USDT, BTC)
        'fiat_type': "Fiat Type",          # Nombre para moneda fiduciaria (ej. USD, UYU)
        'total_price': "Total Price",        # Nombre para el monto total en fiat de la operaci√≥n
        'price': "Price",                # Nombre para el precio unitario
        'quantity': "Quantity",            # Nombre para la cantidad de activo
        'status': "Status",              # Nombre para el estado de la orden
        'match_time_utc': "Match time(UTC)", # Nombre para la fecha/hora de la operaci√≥n en UTC
        'payment_method': "Payment Method",   # Nombre para el m√©todo de pago
        'maker_fee': "Maker Fee",          # Nombre para la comisi√≥n del maker
        'taker_fee': "Taker Fee",          # Nombre para la comisi√≥n del taker
        'sale_value_reference_fiat': None # (Opcional, no usado activamente) Fiat para referenciar valor de venta
    },
    'sell_operation': {
        'indicator_column': "order_type",   # Columna interna usada para identificar ventas
        'indicator_value': "SELL"           # Valor en 'indicator_column' que significa venta
    },
    'reference_fiat_for_sales_summary': "USD", # Fiat de referencia para res√∫menes (uso limitado actual)
    'html_report': {
        'include_tables_default': ["asset_stats", "fiat_stats"], # Claves de m√©tricas a incluir como tablas en HTML
        'include_figures_default': ["hourly_operations"]       # (Placeholder) Idea futura: seleccionar figuras por defecto
    }
}
```

**Secciones de `DEFAULT_CONFIG`:**

*   **`column_mapping`**:
    *   **Prop√≥sito:** Permite al script adaptarse a archivos CSV que puedan tener nombres de columna ligeramente diferentes a los esperados internamente.
    *   **Uso:** Las claves del diccionario son los nombres *internos* que el script usa consistentemente (ej. `order_type`). Los valores son los nombres de columna *esperados en el archivo CSV de entrada*. Durante la carga inicial en `app.py`, las columnas del CSV se renombran a estos nombres internos.
    *   **Personalizaci√≥n:** Si tu CSV usa "Tipo de Orden" en lugar de "Order Type", simplemente cambiar√≠as `'order_type': "Order Type"` por `'order_type': "Tipo de Orden"`.

*   **`sell_operation`**:
    *   **Prop√≥sito:** Define c√≥mo el script identifica las operaciones de venta, necesario para m√©tricas como `sales_summary_all_assets_fiat_detailed`.
    *   **Uso:**
        *   `indicator_column`: Especifica el nombre *interno* de la columna que contiene la informaci√≥n de si una orden es compra o venta (por defecto, `'order_type'`, que viene del mapeo).
        *   `indicator_value`: Especifica el valor dentro de `indicator_column` que identifica una operaci√≥n de venta (por defecto, `"SELL"`).
    *   **Personalizaci√≥n:** Si tus datos marcan las ventas con "Venta" en la columna "TipoOperacion" (y has mapeado "TipoOperacion" a `order_type`), cambiar√≠as `indicator_value` a `"Venta"`.

*   **`reference_fiat_for_sales_summary`**:
    *   **Prop√≥sito:** Originalmente pensado para normalizar o presentar res√∫menes de ventas en un fiat de referencia com√∫n.
    *   **Uso Actual:** Limitado. El script actualmente no realiza conversiones de moneda basadas en este valor. Es m√°s un placeholder para funcionalidad futura.

*   **`html_report`**:
    *   **Prop√≥sito:** Controla qu√© contenido se incluye por defecto en los reportes HTML generados.
    *   **Uso:**
        *   `include_tables_default`: Una lista de strings. Cada string es una clave del diccionario de m√©tricas devuelto por `analyzer.analyze` (ej. `"asset_stats"`, `"fiat_stats"`). Solo estas tablas se incluir√°n en el reporte HTML.
        *   `include_figures_default`: Pensado para una funcionalidad similar para las figuras, pero actualmente las figuras se incluyen basadas en su generaci√≥n exitosa m√°s que en una lista expl√≠cita aqu√≠.
    *   **Personalizaci√≥n:** Para a√±adir m√°s tablas al HTML (ej. `price_stats`), simplemente a√±ade su clave a la lista `include_tables_default`.

La funci√≥n `load_config()` actualmente solo devuelve una copia de este `DEFAULT_CONFIG`. Para una personalizaci√≥n m√°s avanzada sin modificar el c√≥digo, esta funci√≥n podr√≠a extenderse para leer un archivo de configuraci√≥n externo (ej. `config.yaml`).

## üìä Columnas Clave y Mapeo

La flexibilidad del script para manejar diferentes formatos de CSV se basa en gran medida en el `column_mapping` definido en la configuraci√≥n. El script opera internamente con un conjunto estandarizado de nombres de columna (las claves en `column_mapping`).

**Proceso de Mapeo:**
1.  Al cargar el CSV, `app.py` lee los nombres de las columnas tal como est√°n en el archivo.
2.  Luego, compara estos nombres con los *valores* en `DEFAULT_CONFIG['column_mapping']`.
3.  Si encuentra una coincidencia, renombra la columna del DataFrame al *nombre interno* (la clave correspondiente en `column_mapping`).
    *   Ejemplo: Si el CSV tiene una columna "N√∫mero de Orden" y `column_mapping` tiene `'order_number': "Order Number"`, la columna se renombrar√° internamente a `order_number`.

**Nombres Internos Principales y su Significado (post-mapeo y procesamiento en `analyzer.py`):**

*   `order_number`: Identificador √∫nico de la orden.
*   `order_type`: Tipo de orden (ej. "BUY", "SELL").
*   `asset_type`: Tipo de activo transaccionado (ej. "USDT", "BTC").
*   `fiat_type`: Moneda fiduciaria usada (ej. "USD", "UYU").
*   `total_price`: Valor total de la operaci√≥n en la moneda fiat (num√©rico). Originalmente del CSV, luego `TotalPrice_num`.
*   `price`: Precio unitario del activo en la moneda fiat (num√©rico). Originalmente del CSV, luego `Price_num`.
*   `quantity`: Cantidad del activo transaccionado (num√©rico). Originalmente del CSV, luego `Quantity_num`.
*   `status`: Estado de la orden (ej. "Completed", "Cancelled", "System cancelled").
*   `match_time_utc`: Fecha y hora de la operaci√≥n en UTC (del CSV).
*   `payment_method`: M√©todo de pago usado.
*   `maker_fee`: Comisi√≥n del maker (num√©rico). Originalmente del CSV, luego `MakerFee_num`.
*   `taker_fee`: Comisi√≥n del taker (num√©rico). Originalmente del CSV, luego `TakerFee_num`.
*   `Quantity_num`, `MakerFee_num`, `TakerFee_num`, `Price_num`, `TotalPrice_num`: Columnas num√©ricas (Float64) creadas/validadas en `analyzer.py` a partir de sus contrapartes originales del CSV, despu√©s de aplicar `utils.parse_amount`.
*   `TotalFee`: Suma de `MakerFee_num` y `TakerFee_num`.
*   `Match_time_utc_dt`: Columna `match_time_utc` convertida a tipo datetime de Polars, con zona horaria UTC.
*   `Match_time_local`: Fecha y hora de la operaci√≥n convertida a la zona horaria local (America/Montevideo). Tipo datetime de Polars.
*   `hour_local`: Hora del d√≠a (0-23) extra√≠da de `Match_time_local`.
*   `YearMonthStr`: A√±o y mes (ej. "2023-04") extra√≠do de `Match_time_local`.
*   `Year`: A√±o (ej. 2023) extra√≠do de `Match_time_local`.

Es crucial que el `column_mapping` en la configuraci√≥n refleje correctamente los nombres de las columnas en el archivo CSV de entrada para que el script funcione adecuadamente. Si una columna mapeada no se encuentra en el CSV, `analyzer.py` intentar√° crearla con valores nulos para evitar que el script falle, pero las m√©tricas dependientes de esa columna estar√°n vac√≠as o incompletas.

## üìà M√©tricas Calculadas (`src/analyzer.py`)

La funci√≥n `analyze` en `src/analyzer.py` es responsable de calcular un conjunto diverso de m√©tricas. Estas m√©tricas se devuelven como un diccionario donde las claves son los nombres de las m√©tricas y los valores son DataFrames o Series de Polars.

A continuaci√≥n se detallan las principales m√©tricas generadas:

1.  **`asset_stats`** (DataFrame):
    *   **Agrupaci√≥n:** `asset_type`, `order_type`.
    *   **C√°lculos:**
        *   `operations`: N√∫mero total de operaciones.
        *   `quantity`: Suma total de `Quantity_num` (volumen del activo).
        *   `total_fiat`: Suma total de `TotalPrice_num` (volumen en fiat).
        *   `total_fees`: Suma total de `TotalFee`.
    *   **Ordenado por:** `total_fiat` (descendente).

2.  **`fiat_stats`** (DataFrame):
    *   **Agrupaci√≥n:** `fiat_type`, `order_type`.
    *   **C√°lculos:**
        *   `operations`: N√∫mero total de operaciones.
        *   `total_fiat`: Suma total de `TotalPrice_num`.
        *   `avg_price`: Precio promedio (`Price_num`).
        *   `total_fees`: Suma total de `TotalFee`.
    *   **Ordenado por:** `total_fiat` (descendente).

3.  **`price_stats`** (DataFrame):
    *   **Agrupaci√≥n:** `fiat_type`.
    *   **C√°lculos (sobre `Price_num`):**
        *   `avg_price`: Media.
        *   `median_price`: Mediana.
        *   `min_price`: M√≠nimo.
        *   `max_price`: M√°ximo.
        *   `std_price`: Desviaci√≥n est√°ndar.
        *   `q1_price`: Primer cuartil (Percentil 25).
        *   `q3_price`: Tercer cuartil (Percentil 75).
        *   `iqr_price`: Rango Intercuart√≠lico (Q3 - Q1).
        *   `p1_price`: Percentil 1.
        *   `p99_price`: Percentil 99.

4.  **`fees_stats`** (DataFrame):
    *   **Agrupaci√≥n:** `asset_type`.
    *   **C√°lculos (sobre `TotalFee`):**
        *   `total_fees_collected`: Suma total de comisiones.
        *   `avg_fee_per_op`: Comisi√≥n promedio por operaci√≥n.
        *   `num_ops_with_fees`: N√∫mero de operaciones que tuvieron alguna comisi√≥n (>0).
        *   `max_fee`: Comisi√≥n m√°xima registrada para ese activo.
    *   **Ordenado por:** `total_fees_collected` (descendente).

5.  **`monthly_fiat`** (DataFrame):
    *   **Agrupaci√≥n Inicial:** `YearMonthStr`, `fiat_type`, `order_type`.
    *   **C√°lculo:** Suma de `TotalPrice_num` (volumen en fiat).
    *   **Transformaci√≥n:** Se pivota la tabla para que `YearMonthStr` y `fiat_type` sean el √≠ndice, y haya columnas separadas para los vol√∫menes de "BUY" y "SELL" (u otros `order_type` presentes). Los valores nulos (meses/fiats sin un tipo de orden) se rellenan con 0.

6.  **`status_counts`** (Series o DataFrame de una columna):
    *   **C√°lculo:** Conteo de ocurrencias de cada valor √∫nico en la columna `status`.

7.  **`side_counts`** (Series o DataFrame de una columna):
    *   **C√°lculo:** Conteo de ocurrencias de cada valor √∫nico en la columna `order_type` (normalmente "BUY" y "SELL").

8.  **`hourly_counts`** (DataFrame):
    *   **C√°lculo:** Conteo de ocurrencias de cada valor en la columna `hour_local`.
    *   **Ordenado por:** `hour_local` (ascendente).

9.  **`sales_summary_all_assets_fiat_detailed`** (DataFrame):
    *   **Condici√≥n:** Solo se calcula sobre operaciones con `status == 'Completed'` y que coincidan con la definici√≥n de venta en `config['sell_operation']` (ej. `order_type == 'SELL'`).
    *   **Agrupaci√≥n:** `asset_type` (Asset Sold), `fiat_type` (Fiat Received).
    *   **C√°lculos:**
        *   `Total Asset Sold`: Suma de `Quantity_num`.
        *   `Total Fiat Received`: Suma de `TotalPrice_num`.
        *   `Average Sell Price (in Fiat Received)`: `Total Fiat Received` / `Total Asset Sold`.
    *   **Nota:** Si no hay operaciones de venta completadas, esta m√©trica ser√° un DataFrame vac√≠o.

Todas estas m√©tricas se calculan para cada subconjunto de datos (combinaci√≥n de periodo y estado) procesado por `main_logic.run_analysis_pipeline`.

## üñºÔ∏è Generaci√≥n de Salidas (`src/reporter.py` y `src/plotting.py`)

El m√≥dulo `reporter.py` orquesta la creaci√≥n de todos los archivos de salida, utilizando `plotting.py` para la generaci√≥n de los gr√°ficos.

**1. Tablas (`.csv`)**
   *   Ubicaci√≥n: `output/[periodo]/[estado_subdir]/tables/`
   *   Contenido: Todas las m√©tricas calculadas por `analyzer.py` (descritas en la secci√≥n anterior) se guardan como archivos CSV individuales.
   *   Nombrado: `[nombre_metrica][sufijo_cli].csv` (ej. `asset_stats_general.csv`, `price_stats_fiat_UYU.csv`).

**2. Figuras (`.png`)**
   *   Ubicaci√≥n: `output/[periodo]/[estado_subdir]/figures/`
   *   Generadas por: Funciones en `plotting.py`.
   *   Los gr√°ficos se generan principalmente a partir de los DataFrames de Pandas (convertidos desde Polars en `reporter.py`).
   *   Principales gr√°ficos generados (dependiendo de los datos y la categor√≠a):
        *   **`plot_hourly`**: Gr√°fico de barras mostrando la cantidad de operaciones por cada hora del d√≠a (0-23).
            *   Entrada: M√©trica `hourly_counts`.
            *   Nombre archivo: `hourly_counts[sufijo_cli].png`.
        *   **`plot_monthly`**: Gr√°fico de l√≠neas mostrando el volumen total de fiat (separado por BUY/SELL si aplica) a lo largo de los meses (`YearMonthStr`). Se genera un gr√°fico por cada `fiat_type` principal.
            *   Entrada: M√©trica `monthly_fiat`.
            *   Nombre archivo: `monthly_fiat_volume_[fiat]_[sufijo_cli].png`.
        *   **`plot_pie` (para `side_counts`)**: Gr√°fico de torta mostrando la distribuci√≥n de tipos de orden (BUY vs. SELL).
            *   Entrada: M√©trica `side_counts`.
            *   Nombre archivo: `buy_sell_distribution[sufijo_cli].png`.
        *   **`plot_pie` (para `status_counts`)**: Gr√°fico de torta mostrando la distribuci√≥n de estados de orden.
            *   Entrada: M√©trica `status_counts`.
            *   Nombre archivo: `order_status_distribution[sufijo_cli].png`.
        *   **`plot_price_distribution`** (Solo para datos "Completed"): Histograma y boxplot combinados mostrando la distribuci√≥n de precios (`Price_num`) para pares espec√≠ficos de `asset_type`/`fiat_type` (actualmente hardcodeado para USDT/USD y USDT/UYU en `reporter.py`), diferenciado por `order_type`.
            *   Entrada: `df_completed_for_plots_pandas` (DataFrame de operaciones completadas).
            *   Nombre archivo: `price_distribution_[asset]_[fiat][sufijo_cli].png`.
        *   **`plot_volume_vs_price_scatter`** (Solo para datos "Completed"): Gr√°fico de dispersi√≥n de volumen (`Quantity_num`) vs. precio (`Price_num`) para pares espec√≠ficos de `asset_type`/`fiat_type` (actualmente hardcodeado para USDT/USD y USDT/UYU). El tama√±o de los puntos es proporcional al `TotalPrice_num`. Diferenciado por `order_type`.
            *   Entrada: `df_completed_for_plots_pandas`.
            *   Nombre archivo: `volume_vs_price_scatter_[asset]_[fiat][sufijo_cli].png`.
        *   **`plot_activity_heatmap`**: Heatmap mostrando la concentraci√≥n de operaciones por d√≠a de la semana y hora del d√≠a.
            *   Entrada: `df_to_plot_from_pandas` (el DataFrame principal de la secci√≥n actual, puede ser "todas", "completadas" o "canceladas").
            *   Nombre archivo: `activity_heatmap[sufijo_cli].png`.
        *   (Otras funciones de ploteo como `plot_price_over_time`, `plot_volume_over_time`, `plot_price_vs_payment_method` est√°n definidas en `plotting.py` pero podr√≠an no estar activamente llamadas o ser tan prominentes en `reporter.py` como las listadas arriba, o se llaman para pares espec√≠ficos de forma similar a `plot_price_distribution`).

**3. Reportes (`.html`)**
   *   Ubicaci√≥n: `output/[periodo]/[estado_subdir]/reports/`
   *   Contenido: Un reporte HTML individual para cada combinaci√≥n de periodo y estado.
   *   Generaci√≥n: Usa Jinja2 y la plantilla `templates/report_template.html`.
   *   El reporte incluye:
        *   T√≠tulo din√°mico.
        *   Fecha y hora de generaci√≥n.
        *   Resumen de los filtros CLI aplicados.
        *   Periodo y categor√≠a de estado del reporte.
        *   Tablas HTML seleccionadas (desde `config['html_report']['include_tables_default']`).
        *   Todas las figuras PNG generadas para esa secci√≥n, incrustadas en la p√°gina.
   *   Nombrado: `p2p_sales_report[sufijo_cli].html`.

## üöÄ Uso Avanzado y Argumentos CLI

El script se controla mediante argumentos en la l√≠nea de comandos.

```bash
python src/app.py --csv RUTA_AL_CSV [OPCIONES...]
```

**Argumentos Principales:**

*   `--csv RUTA_CSV` (**Requerido**): Especifica la ruta al archivo CSV que contiene los datos de las operaciones P2P.
*   `--out CARPETA_SALIDA`: (Opcional) Define la carpeta base donde se guardar√°n todos los resultados. Por defecto es `output/`.
*   `--no_annual_breakdown`: (Opcional) Si se incluye este flag, el script **no** realizar√° el desglose por a√±os individuales. Solo procesar√° el conjunto de datos "total" (despu√©s de aplicar los filtros CLI).

**Argumentos de Filtrado (Opcionales):**

Estos filtros se aplican al conjunto de datos **antes** de cualquier desglose por periodo (total/anual) y estado (todas/completadas/canceladas).

*   `--fiat_filter MONEDA1 [MONEDA2 ...]`
    *   Filtra las operaciones para incluir solo aquellas donde la moneda fiat (`fiat_type`) coincida con una o m√°s de las especificadas.
    *   Ejemplo: `--fiat_filter UYU USD` (sensible a may√∫sculas/min√∫sculas seg√∫n los datos, aunque el script intenta normalizar a may√∫sculas para el filtrado).
*   `--asset_filter ACTIVO1 [ACTIVO2 ...]`
    *   Filtra las operaciones para incluir solo aquellas donde el tipo de activo (`asset_type`) coincida con uno o m√°s de los especificados.
    *   Ejemplo: `--asset_filter USDT BTC`
*   `--status_filter ESTADO1 [ESTADO2 ...]`
    *   Filtra las operaciones para incluir solo aquellas cuyo estado (`status`) coincida con uno o m√°s de los especificados.
    *   **Importante:** Este filtro afecta al conjunto de datos *antes* de la segmentaci√≥n interna por `completadas`/`canceladas`/`todas`.
        *   Si, por ejemplo, usas `--status_filter Cancelled "System cancelled"`, entonces la carpeta `output/[periodo]/completadas/` probablemente estar√° vac√≠a, y las carpetas `canceladas/` y `todas/` contendr√°n solo las operaciones canceladas.
        *   Si no se especifica este filtro CLI, la segmentaci√≥n interna (`completadas`, `canceladas`, `todas`) opera sobre todos los estados presentes despu√©s de otros filtros CLI. Para un an√°lisis que considere todos los estados originales en sus respectivas categor√≠as, generalmente es mejor **no** usar este filtro CLI.
*   `--payment_method_filter METODO1 ["METODO CON ESPACIOS" ...]`
    *   Filtra las operaciones para incluir solo aquellas donde el m√©todo de pago (`payment_method`) coincida con uno o m√°s de los especificados. Si un m√©todo de pago tiene espacios, debe ir entre comillas.
    *   Ejemplo: `--payment_method_filter BROU "Prex ARS"`

**Impacto de los Filtros en los Nombres de Archivo:**
Los filtros CLI aplicados se reflejan en los nombres de los archivos de salida (tablas y figuras) y en los t√≠tulos de los reportes HTML, facilitando la identificaci√≥n del conjunto de datos que representan. Por ejemplo, si se usa `--fiat_filter UYU --asset_filter USDT`, un archivo de estad√≠sticas de activos podr√≠a llamarse `asset_stats_fiat_UYU_asset_USDT.csv`. Si no se aplican filtros, se usa el sufijo `_general`.

**Ejemplos Combinados:**

*   Analizar solo operaciones en UYU para el activo USDT, para el a√±o 2023, y guardar en `resultados_especificos`:
    ```bash
    # (El filtrado de a√±o se hace si --no_annual_breakdown no est√° presente y 2023 existe en los datos)
    python src/app.py --csv data/p2p.csv --fiat_filter UYU --asset_filter USDT --out resultados_especificos
    ```

*   Analizar solo operaciones "Completed" y "Cancelled", sin desglose anual:
    ```bash
    python src/app.py --csv data/p2p.csv --status_filter Completed Cancelled --no_annual_breakdown
    ```
    *(Recuerda la nota sobre `--status_filter` y la segmentaci√≥n interna).*


## üë®‚Äçüíª Gu√≠a para Desarrolladores

Esta secci√≥n ofrece pautas para aquellos que deseen modificar o extender la funcionalidad del proyecto.

**1. Entendiendo el Flujo:**
   *   Revisa cuidadosamente las secciones "Arquitectura del C√≥digo Fuente" y "Flujo de Procesamiento de Datos Detallado" de este README.
   *   Sigue el flujo de ejecuci√≥n desde `app.py` -> `main_logic.py` -> `analyzer.py` -> `reporter.py` -> `plotting.py`.

**2. A√±adir Nuevas M√©tricas:**
   *   **Ubicaci√≥n:** Principalmente en `src/analyzer.py`, dentro de la funci√≥n `analyze`.
   *   **Pasos:**
        1.  Aseg√∫rate de que las columnas de Polars necesarias para tu nueva m√©trica existan y est√©n correctamente procesadas (ej. convertidas a num√©ricas, fechas a datetime). Realiza estas transformaciones al principio de la funci√≥n `analyze` si es necesario.
        2.  Escribe la l√≥gica de agregaci√≥n usando las funciones de Polars (ej. `group_by()`, `agg()`, `sum()`, `mean()`, `filter()`, `with_columns()`, etc.).
        3.  Asigna el resultado (un DataFrame o Serie de Polars) a una nueva clave en el diccionario `metrics`.
            ```python
            # En analyzer.py, dentro de analyze()
            # Ejemplo: Nueva m√©trica de conteo por m√©todo de pago
            if payment_method_col in df_processed.columns:
                metrics['payment_method_counts'] = df_processed[payment_method_col].value_counts()
            else:
                metrics['payment_method_counts'] = pl.Series(dtype=pl.datatypes.UInt32).to_frame() # Devolver vac√≠o si no existe
            ```
        4.  **Opcional:** Si quieres que esta nueva tabla aparezca en el reporte HTML por defecto, a√±ade su clave a la lista `include_tables_default` en `DEFAULT_CONFIG` dentro de `src/config_loader.py`.
            ```python
            # En config_loader.py
            'html_report': {
                'include_tables_default': ["asset_stats", "fiat_stats", "payment_method_counts"], # A√±adida nueva m√©trica
                # ...
            }
            ```
        5.  `reporter.py` guardar√° autom√°ticamente esta nueva m√©trica como un archivo CSV.

**3. A√±adir Nuevos Gr√°ficos:**
   *   **Paso 1: Crear la Funci√≥n de Ploteo en `src/plotting.py`**
        1.  Define una nueva funci√≥n, por ejemplo, `plot_mi_nuevo_grafico(df_pandas: pd.DataFrame, out_dir: str, title_suffix: str = "", file_identifier: str = "_general") -> str | None:`.
        2.  La funci√≥n debe tomar un DataFrame de Pandas (ya que `reporter.py` convierte los datos de Polars antes de plotear).
        3.  Implementa la l√≥gica de generaci√≥n del gr√°fico usando `matplotlib.pyplot` y/o `seaborn`.
        4.  Aseg√∫rate de manejar t√≠tulos, etiquetas, leyendas de forma din√°mica usando `title_suffix`.
        5.  Construye el `file_path` completo usando `os.path.join(out_dir, f'nombre_base_grafico{file_identifier}.png')`.
        6.  Guarda el gr√°fico con `plt.savefig(file_path)` y cierra la figura con `plt.close()`.
        7.  Devuelve `file_path` si se guard√≥ correctamente, o `None` si hubo un error o no hab√≠a datos.
        8.  Incluye logging para informar sobre el proceso o errores.
   *   **Paso 2: Llamar a la Nueva Funci√≥n de Ploteo en `src/reporter.py`**
        1.  Dentro de la funci√≥n `save_outputs` en `reporter.py`, despu√©s de la conversi√≥n a Pandas (`df_to_plot_from_pandas = df_to_plot_from.to_pandas(...)` y `metrics_to_save_pandas = {...}`), decide qu√© datos usar√° tu nuevo gr√°fico. Puede ser `df_to_plot_from_pandas` o una de las m√©tricas en `metrics_to_save_pandas`.
        2.  Llama a tu nueva funci√≥n:
            ```python
            # En reporter.py, dentro de save_outputs()
            # Ejemplo:
            # df_para_mi_grafico = metrics_to_save_pandas.get('payment_method_counts') # O el df principal
            # if df_para_mi_grafico is not None and not df_para_mi_grafico.empty:
            #     path_mi_nuevo_grafico = plotting.plot_mi_nuevo_grafico(
            #         df_para_mi_grafico,
            #         figures_dir,
            #         title_suffix=final_title_suffix,
            #         file_identifier=file_name_suffix_from_cli
            #     )
            #     add_figure_to_html_list(path_mi_nuevo_grafico, "T√≠tulo Descriptivo para Mi Nuevo Gr√°fico")
            ```
        3.  La funci√≥n `add_figure_to_html_list` se encarga de a√±adir la ruta y el t√≠tulo del gr√°fico a la lista que se pasa al template HTML.

**4. Modificar la Plantilla HTML (`templates/report_template.html`):**
   *   El reporte se genera usando Jinja2. Puedes modificar `report_template.html` para cambiar la estructura, estilos o informaci√≥n mostrada.
   *   El contexto pasado a la plantilla desde `reporter.py` incluye: `title`, `generation_timestamp`, `current_year`, `applied_filters` (dict), `sales_summary_data` (dict), `included_tables` (lista de dicts con `title` y `html`), `included_figures` (lista de dicts con `title` y `path`).
   *   Puedes usar bucles Jinja2 para iterar sobre `included_tables` e `included_figures`.
        ```html
        {% for table_item in included_tables %}
            <div class="card">
                <h2 class="card-header">{{ table_item.title }}</h2>
                <div class="table-responsive">
                    {{ table_item.html | safe }}
                </div>
            </div>
        {% endfor %}
        ```

**5. Manejo de Dependencias:**
   *   Si a√±ades nuevas bibliotecas, aseg√∫rate de incluirlas en `requirements.txt`.
   *   Ejecuta `pip freeze > requirements.txt` despu√©s de instalar nuevas dependencias en tu entorno virtual para actualizar el archivo.

**6. Consideraciones sobre Polars vs. Pandas:**
   *   La l√≥gica de `analyzer.py` debe usar Polars para el procesamiento de datos y c√°lculo de m√©tricas debido a su eficiencia.
   *   En `reporter.py`, los DataFrames/Series de Polars se convierten a Pandas (`.to_pandas()`) antes de pasarlos a las funciones de `plotting.py` y para la generaci√≥n de tablas HTML con `.to_html()`, ya que Matplotlib/Seaborn y la funcionalidad `to_html` de Pandas est√°n m√°s establecidas.

**7. Logging:**
   *   Utiliza el m√≥dulo `logging` para a√±adir informaci√≥n √∫til sobre el flujo de ejecuci√≥n, advertencias o errores.
   *   Obt√©n un logger al principio de cada m√≥dulo: `logger = logging.getLogger(__name__)`.
   *   Usa diferentes niveles: `logger.info()`, `logger.warning()`, `logger.error()`, `logger.debug()`.

**8. Limpieza de C√≥digo:**
   *   **Eliminar C√≥digo Comentado Innecesario:** Si hay bloques de c√≥digo que han sido comentados y ya no son relevantes o han sido reemplazados por una mejor l√≥gica, es bueno eliminarlas para mejorar la legibilidad.
   *   **Revisar Logs de Depuraci√≥n:** Logs muy detallados o espec√≠ficos de una fase de depuraci√≥n (`logger.debug(...)` o prints) pueden ser eliminados o comentados si no aportan al entendimiento general del flujo en producci√≥n.
   *   **Funciones No Utilizadas:** Si hay funciones definidas que no se llaman desde ninguna parte del flujo activo, considera eliminarlas.

## üîó Dependencias Clave

*   **Polars:** El motor principal para el procesamiento de DataFrames. Proporciona un rendimiento excepcional para la manipulaci√≥n y agregaci√≥n de datos, especialmente con conjuntos de datos de tama√±o considerable. Escrito en Rust, ofrece una API de Python.
*   **Pandas:** Utilizado secundariamente en `reporter.py` para la conversi√≥n final de datos antes de la generaci√≥n de gr√°ficos (ya que Matplotlib/Seaborn tienen una integraci√≥n m√°s directa con Pandas) y para la generaci√≥n de tablas HTML (`to_html()`).
*   **Matplotlib & Seaborn:** Bibliotecas est√°ndar de Python para la creaci√≥n de visualizaciones est√°ticas, interactivas y animadas. Seaborn se basa en Matplotlib y proporciona una interfaz de alto nivel para dibujar gr√°ficos estad√≠sticos atractivos e informativos.
*   **Jinja2:** Un motor de plantillas moderno y amigable para el dise√±ador para Python. Se utiliza para generar los reportes HTML a partir de la plantilla `report_template.html` y los datos calculados.
*   **PyYAML:** (No directamente en el c√≥digo actual pero listado en `requirements.txt` de proyectos anteriores, podr√≠a ser √∫til si la carga de configuraci√≥n se extiende a archivos YAML). Para cargar y guardar archivos YAML.
*   **PyArrow:** Usado internamente por Polars (y Pandas opcionalmente) para un manejo eficiente de la memoria y formatos de datos columnares. `use_pyarrow_extension_array=True` en las conversiones `.to_pandas()` intenta usar tipos de datos respaldados por Arrow para mejor rendimiento y manejo de nulos.

## üîÑ Flujo de Procesamiento de Datos (Resumen Gr√°fico Simplificado)

```mermaid
graph TD
    A["Archivo CSV de Entrada"] --> B("app.py: Carga, Mapeo, Filtro CLI");
    B --> C("analyzer.py: Pre-procesamiento Base <br> ej. Columna 'Year'");
    C -- "df_master_processed" --> D["main_logic.run_analysis_pipeline"];
    D -- "Para cada PERIODO <br> (Total, A&ntilde;o_X, A&ntilde;o_Y...)" --> E{"Itera Periodo"};
    E -- "Para cada ESTADO <br> (Todas, Completadas, Canceladas)" --> F{"Itera Estado"};
    F -- "df_subset = Filtro(df_periodo_base POR estado)" --> G{"df_subset NO VAC&Iacute;O?"};
    G -- "S&iacute;" --> H["analyzer.analyze(df_subset) <br> C&aacute;lculo de M&eacute;tricas Detalladas"];
    H -- "processed_df_for_save, current_metrics" --> I["reporter.save_outputs(...)"];
    I --> J["Guardar Tablas CSV <br> (de current_metrics)"];
    I --> K["plotting.py: Generar Figuras PNG <br> (de processed_df_for_save, current_metrics)"];
    I --> L["Generar Reporte HTML <br> (con tablas y figuras)"];
    G -- "No" --> F;
    F -- "Fin Estados" --> E;
    E -- "Fin Periodos" --> M["Resultados en carpeta 'output/'"];
```

_Diagrama de flujo simplificado que ilustra las etapas principales del procesamiento de datos._
